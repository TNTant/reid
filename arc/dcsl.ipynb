{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "# %reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from lz import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0,'/data1/xinglu/prj/open-reid')\n",
    "from train import * \n",
    "from torch import autograd \n",
    "from torch.nn import  functional as F \n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_dev((3,))\n",
    "dataset, num_classes, train_loader, val_loader, test_loader = get_data(\n",
    "    'cuhk03',0,'/home/xinglu/.torch/data',256,128,8,4,4,True)\n",
    "\n",
    "model=models.create('attention50')\n",
    "# checkpoint=load_checkpoint('./logs.tri.bak/model_best.pth.tar')\n",
    "# model.load_state_dict(checkpoint['state_dict'])\n",
    "# model=nn.DataParallel(model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lz.mkdir_p('graph',delete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048, 8, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer=SummaryWriter('graph/resnet')\n",
    "res=model(torch.autograd.Variable(torch.Tensor(1,3,256,128),requires_grad=True)) \n",
    "res.size()\n",
    "\n",
    "writer.add_graph(model,res)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer=SummaryWriter('graph/resnet.base')\n",
    "res=model.base(torch.autograd.Variable(torch.Tensor(1,3,256,256),requires_grad=True)) \n",
    "res.size()\n",
    "\n",
    "writer.add_graph(model.base,res)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.densenet121()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "class Mnist(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Mnist, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        self.bn = nn.BatchNorm2d(20)\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(self.conv1(x), 2)\n",
    "        x = F.relu(x)+F.relu(-x)\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = self.bn(x)\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x)\n",
    "        return x\n",
    "\n",
    "model = Mnist()\n",
    "\n",
    "# if you want to show the input tensor, set requires_grad=True\n",
    "res = model(torch.autograd.Variable(torch.Tensor(1,1,28,28), requires_grad=True))\n",
    "\n",
    "writer = SummaryWriter('graph/mnist')\n",
    "writer.add_graph(model, res)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_transformer = T.Compose([\n",
    "    T.RectScale(256,128),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "test_loader2 = DataLoader(\n",
    "    Preprocessor(list(set(dataset.query) | set(dataset.gallery)),\n",
    "                 root=dataset.images_dir, transform=test_transformer),\n",
    "    batch_size=8, num_workers=2,\n",
    "    shuffle=False, pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65755181347148428"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = DistanceMetric(algorithm='euclidean')\n",
    "# Evaluator\n",
    "evaluator = Evaluator(model)\n",
    "evaluator.evaluate(test_loader, dataset.query, dataset.gallery, metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metric = DistanceMetric(algorithm='euclidean')\n",
    "# Evaluator\n",
    "evaluator = Evaluator(model)\n",
    "acc = evaluator.evaluate(val_loader, dataset.val, dataset.val, metric,return_all=True)\n",
    "print acc['cuhk03'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1936, 683, 242)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*len(test_loader),len(train_loader),len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256, 128])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(torch.autograd.variable.Variable, torch.FloatTensor)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.size()\n",
    "t=nn.AvgPool2d((4,4))(im)\n",
    "type(t),type(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 'writer' in globals().keys():\n",
    "    writer.close()\n",
    "import lz\n",
    "lz.mkdir_p('./tri.tsne',delete=True)\n",
    "writer=SummaryWriter('./tri.tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 32])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1284"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1930, 128])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=collections.OrderedDict() \n",
    "labels=collections.OrderedDict()\n",
    "images=collections.OrderedDict()\n",
    "for (imgs,fnames,pids,cids), (imgs_ori,_,_,_) in zip(test_loader,test_loader2):\n",
    "#     imgs=torch.from_numpy((imgs)) \n",
    "    imgs=torch.autograd.Variable(imgs,volatile=True)\n",
    "    feas=model(imgs)\n",
    "#     imgs.size(),feas.size()\n",
    "    for name,f,l,im in zip(fnames, feas,pids,imgs_ori):\n",
    "        features[name] =f \n",
    "        labels[name]=l\n",
    "        images[name]=nn.AvgPool2d((4,4))(im).data\n",
    "#     if len(features) > 500:\n",
    "#         break \n",
    "\n",
    "images.values()[0].size()\n",
    "features.values()[0].size( )\n",
    "\n",
    "\n",
    "labels.values()[0]\n",
    "\n",
    "images=torch.stack(images.values()).float()\n",
    "# images=torch.mean(images,1)\n",
    "features = torch.stack(features.values())\n",
    "features.size()\n",
    "labels = np.array(labels.values()) \n",
    "labels = torch.from_numpy(labels) \n",
    "# labels = labels.view((-1,1))\n",
    "labels = torch.autograd.Variable(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1930, 128]), torch.Size([1930]), torch.Size([1930, 3, 64, 32]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.size(),labels.size(),images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer.add_embedding(features.data, metadata=labels.data, label_img=images,global_step=0,tag='test.spirit')        \n",
    "\n",
    "writer.add_embedding(features.data, metadata=labels.data ,global_step=1,tag='test.label')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 128, 3)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im=images[0].numpy().transpose((1,2,0))\n",
    "im.shape\n",
    "\n",
    "im.max(),im.min(),\n",
    "\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 32])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1945, 128])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_transformer = T.Compose([\n",
    "    T.RectScale(256,128),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "val_loader2 = DataLoader(\n",
    "    Preprocessor( dataset.val  ,\n",
    "                 root=dataset.images_dir, transform=test_transformer),\n",
    "    batch_size=8, num_workers=2,\n",
    "    shuffle=False, pin_memory=True)\n",
    "\n",
    "\n",
    "features=collections.OrderedDict() \n",
    "labels=collections.OrderedDict()\n",
    "images=collections.OrderedDict()\n",
    "for (imgs,fnames,pids,cids), (imgs_ori,_,_,_) in zip(val_loader,val_loader2):\n",
    "#     imgs=torch.from_numpy((imgs)) \n",
    "    imgs=torch.autograd.Variable(imgs,volatile=True)\n",
    "    feas=model(imgs)\n",
    "#     imgs.size(),feas.size()\n",
    "    for name,f,l,im in zip(fnames, feas,pids,imgs_ori):\n",
    "        features[name] =f \n",
    "        labels[name]=l\n",
    "        images[name]=nn.AvgPool2d((4,4))(im).data\n",
    "#     if len(features) > 500:\n",
    "#         break \n",
    "\n",
    "images.values()[0].size()\n",
    "features.values()[0].size( )\n",
    "\n",
    "\n",
    "labels.values()[0]\n",
    "\n",
    "images=torch.stack(images.values()).float()\n",
    "# images=torch.mean(images,1)\n",
    "features = torch.stack(features.values())\n",
    "features.size()\n",
    "labels = np.array(labels.values()) \n",
    "labels = torch.from_numpy(labels) \n",
    "# labels = labels.view((-1,1))\n",
    "labels = torch.autograd.Variable(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer.add_embedding(features.data, metadata=labels.data, label_img=images,global_step=3,tag='train.spirit')        \n",
    "\n",
    "writer.add_embedding(features.data, metadata=labels.data ,global_step=4,tag='train.label')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
